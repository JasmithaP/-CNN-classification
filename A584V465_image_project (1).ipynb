{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b8cdca72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import necessary libraries to perform binary image classification\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score,precision_score\n",
    "import os\n",
    "import cv2\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e5dc50cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1376 images belonging to 2 classes.\n",
      "Found 294 images belonging to 2 classes.\n",
      "Found 296 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#Path to the dataset in our system\n",
    "path = \"C:/Users/panug/Downloads/pizza_not_pizza\"\n",
    "\n",
    "#Data augmentation helps making the model more robust and generalizing it.\n",
    "#Imagedatagenerator is used for data augmentation and preprocessing.\n",
    "\n",
    "## Creating image data generators for the train sets\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,rotation_range=30, \n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest')\n",
    "\n",
    "#load training dataset\n",
    "train_set = train_datagen.flow_from_directory(os.path.join(path, 'train'),\n",
    "                                              target_size=(150,150),\n",
    "                                              batch_size=32,\n",
    "\n",
    "                                              class_mode='binary')\n",
    "\n",
    "#Creating image data generators for the val sets\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "#load validation dataset\n",
    "val_set = val_datagen.flow_from_directory(os.path.join(path, 'val'),\n",
    "                                          target_size=(150,150),\n",
    "                                          batch_size=32,\n",
    "                                          class_mode='binary')\n",
    "\n",
    "#Creating image data generators for the test sets\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "#load test dataset\n",
    "test_set = test_datagen.flow_from_directory(os.path.join(path, 'test'),\n",
    "                                            target_size=(150,150),\n",
    "                                            batch_size=32,\n",
    "                                            class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "58ae9f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the cnn model\n",
    "model = Sequential([\n",
    "    #The convolutional layers\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(110, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    #Fully connected layer s and dense layers\n",
    "    Flatten(),\n",
    "    Dense(400, activation='relu'),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dense(1, activation='sigmoid') #output layer(sigmoid is used for binary classification)\n",
    "]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "84edaf1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_32 (Conv2D)          (None, 148, 148, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d_32 (MaxPoolin  (None, 74, 74, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_33 (Conv2D)          (None, 72, 72, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_33 (MaxPoolin  (None, 36, 36, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_34 (Conv2D)          (None, 34, 34, 110)       63470     \n",
      "                                                                 \n",
      " max_pooling2d_34 (MaxPoolin  (None, 17, 17, 110)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_35 (Conv2D)          (None, 15, 15, 128)       126848    \n",
      "                                                                 \n",
      " max_pooling2d_35 (MaxPoolin  (None, 7, 7, 128)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_7 (Flatten)         (None, 6272)              0         \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 400)               2509200   \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 512)               205312    \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,924,735\n",
      "Trainable params: 2,924,735\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#print the built cnn model summary \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7f029b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9e8b106b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "43/43 [==============================] - 20s 452ms/step - loss: 0.6994 - accuracy: 0.5182 - val_loss: 0.6819 - val_accuracy: 0.5510\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 19s 438ms/step - loss: 0.6962 - accuracy: 0.5843 - val_loss: 0.6916 - val_accuracy: 0.5000\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 18s 415ms/step - loss: 0.6661 - accuracy: 0.5828 - val_loss: 0.6107 - val_accuracy: 0.6701\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 18s 426ms/step - loss: 0.6345 - accuracy: 0.6555 - val_loss: 0.5722 - val_accuracy: 0.7245\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 18s 426ms/step - loss: 0.6340 - accuracy: 0.6475 - val_loss: 0.5270 - val_accuracy: 0.7347\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 18s 424ms/step - loss: 0.5707 - accuracy: 0.7020 - val_loss: 0.7963 - val_accuracy: 0.5782\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 18s 422ms/step - loss: 0.5579 - accuracy: 0.7144 - val_loss: 0.5087 - val_accuracy: 0.7823\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 18s 416ms/step - loss: 0.5249 - accuracy: 0.7507 - val_loss: 0.4606 - val_accuracy: 0.8095\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 18s 412ms/step - loss: 0.5039 - accuracy: 0.7515 - val_loss: 0.5187 - val_accuracy: 0.7721\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 18s 411ms/step - loss: 0.4808 - accuracy: 0.7791 - val_loss: 0.4746 - val_accuracy: 0.7857\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 18s 412ms/step - loss: 0.4873 - accuracy: 0.7762 - val_loss: 0.4737 - val_accuracy: 0.8061\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 19s 441ms/step - loss: 0.4701 - accuracy: 0.7783 - val_loss: 0.5079 - val_accuracy: 0.7381\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 20s 452ms/step - loss: 0.4787 - accuracy: 0.7653 - val_loss: 0.4484 - val_accuracy: 0.8231\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 19s 429ms/step - loss: 0.4379 - accuracy: 0.8001 - val_loss: 0.5181 - val_accuracy: 0.7449\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 18s 422ms/step - loss: 0.4374 - accuracy: 0.7965 - val_loss: 0.5601 - val_accuracy: 0.7415\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 18s 424ms/step - loss: 0.4502 - accuracy: 0.7951 - val_loss: 0.4063 - val_accuracy: 0.8197\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 18s 426ms/step - loss: 0.4353 - accuracy: 0.8001 - val_loss: 0.4529 - val_accuracy: 0.8367\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 18s 420ms/step - loss: 0.4468 - accuracy: 0.8045 - val_loss: 0.4150 - val_accuracy: 0.8367\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 18s 418ms/step - loss: 0.4112 - accuracy: 0.8183 - val_loss: 0.4036 - val_accuracy: 0.8299\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 18s 418ms/step - loss: 0.4075 - accuracy: 0.8176 - val_loss: 0.4842 - val_accuracy: 0.7823\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "#no.of epochs\n",
    "cnn = model.fit(train_set,epochs=20, validation_data=val_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "50866f97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 8s 181ms/step - loss: 0.4191 - accuracy: 0.8001\n",
      "10/10 [==============================] - 1s 82ms/step - loss: 0.4842 - accuracy: 0.7823\n",
      "10/10 [==============================] - 1s 83ms/step - loss: 0.5070 - accuracy: 0.7466\n"
     ]
    }
   ],
   "source": [
    "#evaluate the train,validation and test loss and accuracies respectively\n",
    "train_loss, train_accuracy = model.evaluate(train_set)\n",
    "val_loss, validation_accuracy = model.evaluate(val_set)\n",
    "test_loss, test_accuracy = model.evaluate(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7dffc552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.8001453280448914\n",
      "Validation accuracy: 0.7823129296302795\n",
      "Test accuracy: 0.7466216087341309\n"
     ]
    }
   ],
   "source": [
    "# Print the accuracies\n",
    "print('Train accuracy:', train_accuracy)\n",
    "print('Validation accuracy:', validation_accuracy)\n",
    "print('Test accuracy:', test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5d599f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 1s 84ms/step\n",
      "F1 score value for cnn:  0.5889212827988339\n",
      "Precision value for cnn:  0.517948717948718\n",
      "Recall value for cnn:  0.6824324324324325\n"
     ]
    }
   ],
   "source": [
    "#calculating the precision values\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "#predicting the results\n",
    "y_pred = model.predict(test_set)\n",
    "\n",
    "#rounding the result values to 1 if >0.5 and 0 if <0.5\n",
    "y_pred = (y_pred > 0.5).astype(int)\n",
    "y_true = test_set.classes\n",
    "\n",
    "\n",
    "#calculate precision value\n",
    "precision = precision_score(y_true, y_pred)\n",
    "\n",
    "#calculate recall value\n",
    "recall = recall_score(y_true, y_pred)\n",
    "\n",
    "#calculate f1 score\n",
    "f1cnn = f1_score(y_true, y_pred)\n",
    "\n",
    "print('F1 score value for cnn: ',f1cnn)\n",
    "print('Precision value for cnn: ', precision)\n",
    "print('Recall value for cnn: ', recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a7f1be33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dense_20\n",
      "10/10 [==============================] - 1s 91ms/step\n",
      "Found 296 images belonging to 2 classes.\n",
      "10/10 [==============================] - 1s 93ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.62      0.59       148\n",
      "           1       0.58      0.51      0.54       148\n",
      "\n",
      "    accuracy                           0.57       296\n",
      "   macro avg       0.57      0.57      0.57       296\n",
      "weighted avg       0.57      0.57      0.57       296\n",
      "\n",
      "Test accuracy 0.5675675675675675\n",
      "f1score 0.5428571428571428\n",
      "recall 0.5135135135135135\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "#consider the fully connected choosing to extract the features(dense_20)\n",
    "layer_name = model.layers[-3].name\n",
    "print(layer_name)\n",
    "\n",
    "output_layer = model.get_layer(layer_name)\n",
    "#Extract the features from the fully connected layer\n",
    "train_svm = keras.models.Model(inputs=model.input, outputs=output_layer.output)\n",
    "\n",
    "#Extract the features from the validation set as asked in the question\n",
    "X_train = train_svm.predict(val_set)\n",
    "y_train = val_set.classes\n",
    "\n",
    "##Train the non-linear svm on the current train dataset\n",
    "svm = SVC(kernel='rbf', C=1.0, gamma='scale')\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_set = test_datagen.flow_from_directory(os.path.join(data_path, 'test'),\n",
    "                                            target_size=(150,150),\n",
    "                                            batch_size=32,\n",
    "                                            class_mode='binary')\n",
    "#Like in the question,extract the features from the same fully connected layer and use as test dataset\n",
    "X_test = train_svm.predict(test_set)\n",
    "y_test = test_set.classes\n",
    "\n",
    "# Evaluate SVM classifier on test set\n",
    "y_pred = svm.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "#evaluate the metrics\n",
    "test_accuracy=accuracy_score(y_test,y_pred)\n",
    "f1score=f1_score(y_test, y_pred)\n",
    "recall=recall_score(y_test, y_pred)\n",
    "#print the obtained test accuracy\n",
    "print(\"Test accuracy\",test_accuracy)\n",
    "print(\"f1score\",f1score)\n",
    "print(\"recall\",recall)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9947011",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
